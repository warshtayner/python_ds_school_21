{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iBJxV7kqcxhz",
    "outputId": "7db481ea-d72b-4848-d29c-dc22106ae61d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.core.display import Image, display\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import pylab as pl\n",
    "import re\n",
    "import codecs\n",
    "import nltk\n",
    "import pymorphy2\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzHcJiO_cxh1"
   },
   "source": [
    "---\n",
    "\n",
    "## Семантический анализ твитов\n",
    "\n",
    "Сегодня мы построим классификатор, который будет разделять текст на позитивные и негативные высказывания. Для этого мы воспользуемся уже размеченной базой.\n",
    "Загрузим данные для анализа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvWtVri3t5fD"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jwYGt9PtvyN"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive  # если вы выполняете код из среды Google Colab, нужно подключить свой гугл-диск,\n",
    "drive.mount('/content/drive')   # чтобы можно было оттуда считать файл с данными для этого задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "l9xDxvzacxh3",
    "outputId": "617ab205-392d-423f-d40c-abac3a53fa64",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>positive</th>\n",
       "      <th>rep</th>\n",
       "      <th>rtv</th>\n",
       "      <th>fav</th>\n",
       "      <th>total_count</th>\n",
       "      <th>fol</th>\n",
       "      <th>friends</th>\n",
       "      <th>list_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.089069e+17</td>\n",
       "      <td>1386325965</td>\n",
       "      <td>fantanshik</td>\n",
       "      <td>RT @Abdullin_A_R: @LikhodedovaMary эхх, а в УГ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2074</td>\n",
       "      <td>82</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.089069e+17</td>\n",
       "      <td>1386325965</td>\n",
       "      <td>Tienn_En</td>\n",
       "      <td>@marinaysol а, а то подумала, что у тебя там п...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6362</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.089069e+17</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>bstrd666</td>\n",
       "      <td>@xLesherx @4EU3 зря вы с этой хуйней шутите)) ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13431</td>\n",
       "      <td>473</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.089069e+17</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>esken_h</td>\n",
       "      <td>@Moscow_advokat Очень главное спасибо for   МЕ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126795</td>\n",
       "      <td>581</td>\n",
       "      <td>86</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.089069e+17</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>Obrazcova98</td>\n",
       "      <td>У нас есть прекрасная история, как сдохнуть за...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>492</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.089068e+17</td>\n",
       "      <td>1386325944</td>\n",
       "      <td>dugarchikbellko</td>\n",
       "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8064</td>\n",
       "      <td>111</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.089068e+17</td>\n",
       "      <td>1386325957</td>\n",
       "      <td>nugemycejela</td>\n",
       "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.089069e+17</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>4post21</td>\n",
       "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>718</td>\n",
       "      <td>49</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.089069e+17</td>\n",
       "      <td>1386325980</td>\n",
       "      <td>Poliwake</td>\n",
       "      <td>Желаю хорошего полёта и удачной посадки,я буду...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10628</td>\n",
       "      <td>207</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.089069e+17</td>\n",
       "      <td>1386325980</td>\n",
       "      <td>capyvixowe</td>\n",
       "      <td>Обновил за каким-то лешим surf, теперь не рабо...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id        date             name  \\\n",
       "16  4.089069e+17  1386325965       fantanshik   \n",
       "17  4.089069e+17  1386325965         Tienn_En   \n",
       "18  4.089069e+17  1386325966         bstrd666   \n",
       "19  4.089069e+17  1386325966          esken_h   \n",
       "20  4.089069e+17  1386325966      Obrazcova98   \n",
       "21  4.089068e+17  1386325944  dugarchikbellko   \n",
       "22  4.089068e+17  1386325957     nugemycejela   \n",
       "23  4.089069e+17  1386325966          4post21   \n",
       "24  4.089069e+17  1386325980         Poliwake   \n",
       "25  4.089069e+17  1386325980       capyvixowe   \n",
       "\n",
       "                                                 text  positive  rep  rtv  \\\n",
       "16  RT @Abdullin_A_R: @LikhodedovaMary эхх, а в УГ...         1    0    1   \n",
       "17  @marinaysol а, а то подумала, что у тебя там п...         1    0    0   \n",
       "18  @xLesherx @4EU3 зря вы с этой хуйней шутите)) ...         1    0    0   \n",
       "19  @Moscow_advokat Очень главное спасибо for   МЕ...         1    0    0   \n",
       "20  У нас есть прекрасная история, как сдохнуть за...         1    0    0   \n",
       "21  на работе был полный пиддес :| и так каждое за...        -1    0    0   \n",
       "22  Коллеги сидят рубятся в Urban terror, а я из-з...        -1    0    0   \n",
       "23  @elina_4post как говорят обещаного три года жд...        -1    0    0   \n",
       "24  Желаю хорошего полёта и удачной посадки,я буду...        -1    0    0   \n",
       "25  Обновил за каким-то лешим surf, теперь не рабо...        -1    0    0   \n",
       "\n",
       "    fav  total_count  fol  friends  list_count  \n",
       "16    0         2074   82       44           5  \n",
       "17    0         6362   30       28           1  \n",
       "18    0        13431  473      111           2  \n",
       "19    0       126795  581       86          10  \n",
       "20    0          492   14       23           0  \n",
       "21    0         8064  111       94           2  \n",
       "22    0           26   42       39           0  \n",
       "23    0          718   49      249           0  \n",
       "24    0        10628  207      200           0  \n",
       "25    0           35   17       34           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data-samples/tweets_example.xlsx')\n",
    "df.loc[16:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'name', 'text', 'positive', 'rep', 'rtv', 'fav',\n",
       "       'total_count', 'fol', 'friends', 'list_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LPhxl7Ucxh3"
   },
   "source": [
    "---\n",
    "\n",
    "Все колонки таблицы могут содержать информацию о тональности твита, но мы будем ориентироваться исключительно на текст и на столбец отнесения к классу positiv.\n",
    "Заменим значение -1 в колонке positive на 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VBRASFNcxh4",
    "outputId": "1c2f5a7a-2607-4314-de5e-dd2574ba4433"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>positive</th>\n",
       "      <th>rep</th>\n",
       "      <th>rtv</th>\n",
       "      <th>fav</th>\n",
       "      <th>total_count</th>\n",
       "      <th>fol</th>\n",
       "      <th>friends</th>\n",
       "      <th>list_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>408906854803451904</td>\n",
       "      <td>1386325965</td>\n",
       "      <td>fantanshik</td>\n",
       "      <td>RT @Abdullin_A_R: @LikhodedovaMary эхх, а в УГ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2074</td>\n",
       "      <td>82</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>408906854849204224</td>\n",
       "      <td>1386325965</td>\n",
       "      <td>Tienn_En</td>\n",
       "      <td>@marinaysol а, а то подумала, что у тебя там п...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6362</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>408906855146983424</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>bstrd666</td>\n",
       "      <td>@xLesherx @4EU3 зря вы с этой хуйней шутите)) ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13431</td>\n",
       "      <td>473</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>408906857659392000</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>esken_h</td>\n",
       "      <td>@Moscow_advokat Очень главное спасибо for   МЕ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126795</td>\n",
       "      <td>581</td>\n",
       "      <td>86</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>408906857982726080</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>Obrazcova98</td>\n",
       "      <td>У нас есть прекрасная история, как сдохнуть за...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>492</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>408906762813579328</td>\n",
       "      <td>1386325944</td>\n",
       "      <td>dugarchikbellko</td>\n",
       "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8064</td>\n",
       "      <td>111</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>408906818262687680</td>\n",
       "      <td>1386325957</td>\n",
       "      <td>nugemycejela</td>\n",
       "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>408906858515398720</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>4post21</td>\n",
       "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>718</td>\n",
       "      <td>49</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>408906914437685184</td>\n",
       "      <td>1386325980</td>\n",
       "      <td>Poliwake</td>\n",
       "      <td>Желаю хорошего полёта и удачной посадки,я буду...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10628</td>\n",
       "      <td>207</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>408906914723295232</td>\n",
       "      <td>1386325980</td>\n",
       "      <td>capyvixowe</td>\n",
       "      <td>Обновил за каким-то лешим surf, теперь не рабо...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id        date             name  \\\n",
       "16  408906854803451904  1386325965       fantanshik   \n",
       "17  408906854849204224  1386325965         Tienn_En   \n",
       "18  408906855146983424  1386325966         bstrd666   \n",
       "19  408906857659392000  1386325966          esken_h   \n",
       "20  408906857982726080  1386325966      Obrazcova98   \n",
       "21  408906762813579328  1386325944  dugarchikbellko   \n",
       "22  408906818262687680  1386325957     nugemycejela   \n",
       "23  408906858515398720  1386325966          4post21   \n",
       "24  408906914437685184  1386325980         Poliwake   \n",
       "25  408906914723295232  1386325980       capyvixowe   \n",
       "\n",
       "                                                 text  positive  rep  rtv  \\\n",
       "16  RT @Abdullin_A_R: @LikhodedovaMary эхх, а в УГ...         1    0    1   \n",
       "17  @marinaysol а, а то подумала, что у тебя там п...         1    0    0   \n",
       "18  @xLesherx @4EU3 зря вы с этой хуйней шутите)) ...         1    0    0   \n",
       "19  @Moscow_advokat Очень главное спасибо for   МЕ...         1    0    0   \n",
       "20  У нас есть прекрасная история, как сдохнуть за...         1    0    0   \n",
       "21  на работе был полный пиддес :| и так каждое за...         0    0    0   \n",
       "22  Коллеги сидят рубятся в Urban terror, а я из-з...         0    0    0   \n",
       "23  @elina_4post как говорят обещаного три года жд...         0    0    0   \n",
       "24  Желаю хорошего полёта и удачной посадки,я буду...         0    0    0   \n",
       "25  Обновил за каким-то лешим surf, теперь не рабо...         0    0    0   \n",
       "\n",
       "    fav  total_count  fol  friends  list_count  \n",
       "16    0         2074   82       44           5  \n",
       "17    0         6362   30       28           1  \n",
       "18    0        13431  473      111           2  \n",
       "19    0       126795  581       86          10  \n",
       "20    0          492   14       23           0  \n",
       "21    0         8064  111       94           2  \n",
       "22    0           26   42       39           0  \n",
       "23    0          718   49      249           0  \n",
       "24    0        10628  207      200           0  \n",
       "25    0           35   17       34           0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.positive[df.positive==-1]=0\n",
    "df.loc[16:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6guuzB4cxh4"
   },
   "source": [
    "-----\n",
    "\n",
    "# Задание 1\n",
    "\n",
    "1. С помощью *pd.read_csv()* загрузите датафреймы positive.csv и negative.csv (обратите внимание, что исходные таблицы не содержат наименования столбцов и на первой строке располагаются данные. Файлы расположены в папке datasets);\n",
    "2. Объедините датафреймы с помощью *pd.concat()* в один датафрейм;\n",
    "3. Убедитесь, что в новом датафрейме индексация сквозная и без повторов;\n",
    "4. Переименуйте столбцы датафрейма (столбцы полностью соответствуют примеру);\n",
    "5. Выведите информацию об общем количестве полученных твитов, сколько из них негативных, сколько позитивных.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJ6Uu0l_cxh5"
   },
   "source": [
    "### Очистка и предобработка данных\n",
    "\n",
    "Перед разработкой классификатора нам необходимо очистить и предобработать данные.\n",
    "\n",
    "Начнем с очистки данных\n",
    "\n",
    "----------------------------\n",
    "\n",
    "***Внимание!*** Библиотека [*nltk*](https://www.nltk.org) может содержать не все компоненты. В случае возникновения ошибки необходимо запустить скрипт\n",
    "\n",
    "*import nltk   \n",
    "nltk.download()*\n",
    "\n",
    "В открывшемся окне необходимо выбрать и установить требуемые компоненты\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dF-tFibCcxh6"
   },
   "source": [
    "Приведем весь текст к строчным буквам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXe5Z7Btcxh6",
    "outputId": "291a5169-ecda-4f33-8907-b6f08b17f3dd",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    @moscow_advokat очень главное спасибо for   ме...\n",
       "20    у нас есть прекрасная история, как сдохнуть за...\n",
       "21    на работе был полный пиддес :| и так каждое за...\n",
       "22    коллеги сидят рубятся в urban terror, а я из-з...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text = df.text.str.lower()\n",
    "df.text.loc[19:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Dj3naj-cxh8"
   },
   "source": [
    "---\n",
    "\n",
    "Оставим в тексте только русские слова, удалив числа, знаки препинания, специальные символы и слова написанные латиницей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FuLUqMv5cxh9",
    "outputId": "88360606-f232-499f-a017-7b205f9ae3e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19                    очень главное спасибо       ме...\n",
       "20    у нас есть прекрасная история  как сдохнуть за...\n",
       "21    на работе был полный пиддес    и так каждое за...\n",
       "22    коллеги сидят рубятся в               а я из з...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text = df.text.str.replace(r\"[^А-Яа-я]\",\" \")\n",
    "df.text.loc[19:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "he1YbhVvcxh9"
   },
   "source": [
    "---\n",
    "\n",
    "Мы анализируем русскоязычный твиттер, поэтому английские слова, а так же числа, будут представлять частные случаи и формировать шум в данных. Но могут возникнуть задачи, где удаляемые слова и числа важны. В этом случае потребуется более взвешенный подход к очистке. Вам могут помочь [константы модуля *string*](https://docs.python.org/3/library/string.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuCaIjPScxh-"
   },
   "source": [
    "Разобьем тексты на слова с помощью *word_tokenize*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJA_VuZ5cxh-",
    "outputId": "430eedd8-7157-4156-9eeb-7be32611c788"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    [очень, главное, спасибо, медвед, он, работал,...\n",
       "20    [у, нас, есть, прекрасная, история, как, сдохн...\n",
       "21    [на, работе, был, полный, пиддес, и, так, кажд...\n",
       "22    [коллеги, сидят, рубятся, в, а, я, из, за, дол...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "df.text = list(map(word_tokenize, df.text))\n",
    "df.text.loc[19:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6w3LiQIfcxh_"
   },
   "source": [
    "---\n",
    "\n",
    "В каждом языке имеются так называемые стоп-слова - это, например, предлоги, союзы, местоимения и т.д. Стоп-слова не несут смысловой нагрузки, но при этом встречаются достаточно часто. Существует множество словарей стоп-слов, мы воспользуемся словарем библиотеки *nltk*. При решении конкретных задач вы можете как расширить словарь стоп-слов, так и удалить из него любые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "4focLj2Hcxh_",
    "outputId": "290cf0df-7f02-4782-8e05-a7f4fdf6058a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['а',\n",
       " 'без',\n",
       " 'более',\n",
       " 'больше',\n",
       " 'будет',\n",
       " 'будто',\n",
       " 'бы',\n",
       " 'был',\n",
       " 'была',\n",
       " 'были',\n",
       " 'было',\n",
       " 'быть',\n",
       " 'в',\n",
       " 'вам',\n",
       " 'вас',\n",
       " 'вдруг',\n",
       " 'ведь',\n",
       " 'во',\n",
       " 'вот',\n",
       " 'впрочем',\n",
       " 'все',\n",
       " 'всегда',\n",
       " 'всего',\n",
       " 'всех',\n",
       " 'всю',\n",
       " 'вы',\n",
       " 'где',\n",
       " 'да',\n",
       " 'даже',\n",
       " 'два',\n",
       " 'для',\n",
       " 'до',\n",
       " 'другой',\n",
       " 'его',\n",
       " 'ее',\n",
       " 'ей',\n",
       " 'ему',\n",
       " 'если',\n",
       " 'есть',\n",
       " 'еще',\n",
       " 'ж',\n",
       " 'же',\n",
       " 'за',\n",
       " 'зачем',\n",
       " 'здесь',\n",
       " 'и',\n",
       " 'из',\n",
       " 'или',\n",
       " 'им',\n",
       " 'иногда',\n",
       " 'их',\n",
       " 'к',\n",
       " 'как',\n",
       " 'какая',\n",
       " 'какой',\n",
       " 'когда',\n",
       " 'конечно',\n",
       " 'кто',\n",
       " 'куда',\n",
       " 'ли',\n",
       " 'лучше',\n",
       " 'между',\n",
       " 'меня',\n",
       " 'мне',\n",
       " 'много',\n",
       " 'может',\n",
       " 'можно',\n",
       " 'мой',\n",
       " 'моя',\n",
       " 'мы',\n",
       " 'на',\n",
       " 'над',\n",
       " 'надо',\n",
       " 'наконец',\n",
       " 'нас',\n",
       " 'не',\n",
       " 'него',\n",
       " 'нее',\n",
       " 'ней',\n",
       " 'нельзя',\n",
       " 'нет',\n",
       " 'ни',\n",
       " 'нибудь',\n",
       " 'никогда',\n",
       " 'ним',\n",
       " 'них',\n",
       " 'ничего',\n",
       " 'но',\n",
       " 'ну',\n",
       " 'о',\n",
       " 'об',\n",
       " 'один',\n",
       " 'он',\n",
       " 'она',\n",
       " 'они',\n",
       " 'опять',\n",
       " 'от',\n",
       " 'перед',\n",
       " 'по',\n",
       " 'под',\n",
       " 'после',\n",
       " 'потом',\n",
       " 'потому',\n",
       " 'почти',\n",
       " 'при',\n",
       " 'про',\n",
       " 'раз',\n",
       " 'разве',\n",
       " 'с',\n",
       " 'сам',\n",
       " 'свою',\n",
       " 'себе',\n",
       " 'себя',\n",
       " 'сейчас',\n",
       " 'со',\n",
       " 'совсем',\n",
       " 'так',\n",
       " 'такой',\n",
       " 'там',\n",
       " 'тебя',\n",
       " 'тем',\n",
       " 'теперь',\n",
       " 'то',\n",
       " 'тогда',\n",
       " 'того',\n",
       " 'тоже',\n",
       " 'только',\n",
       " 'том',\n",
       " 'тот',\n",
       " 'три',\n",
       " 'тут',\n",
       " 'ты',\n",
       " 'у',\n",
       " 'уж',\n",
       " 'уже',\n",
       " 'хорошо',\n",
       " 'хоть',\n",
       " 'чего',\n",
       " 'чем',\n",
       " 'через',\n",
       " 'что',\n",
       " 'чтоб',\n",
       " 'чтобы',\n",
       " 'чуть',\n",
       " 'эти',\n",
       " 'этого',\n",
       " 'этой',\n",
       " 'этом',\n",
       " 'этот',\n",
       " 'эту',\n",
       " 'я']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "russian_stopwords.sort()\n",
    "russian_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stwsz6MFcxh_"
   },
   "source": [
    "---\n",
    "\n",
    "Удалим стоп-слова из наших данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGSeR8VNcxiA",
    "outputId": "7ef5a995-90f6-42d7-f6d0-b03dfa7e3cfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    [очень, главное, спасибо, медвед, работал, кло...\n",
       "20              [прекрасная, история, сдохнуть, неделю]\n",
       "21    [работе, полный, пиддес, каждое, закрытие, мес...\n",
       "22    [коллеги, сидят, рубятся, долбанной, винды, могу]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def delete_stopword(words):\n",
    "    global russian_stopwords\n",
    "    new_s = [word for word in words if word not in russian_stopwords]\n",
    "    return new_s\n",
    "\n",
    "df.text = list(map(delete_stopword, df.text))\n",
    "df.text.loc[19:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2bgmKDkcxiA"
   },
   "source": [
    "---\n",
    "\n",
    "Проведем [лемматизацию](https://ru.wikipedia.org/wiki/Лемматизация) полученных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00mHnfBdcxiB",
    "outputId": "54ea747e-b2c5-4924-b6e5-8d0862b52d52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    [очень, главный, спасибо, медведа, работать, к...\n",
       "20              [прекрасный, история, сдохнуть, неделя]\n",
       "21    [работа, полный, пиддес, каждый, закрытие, мес...\n",
       "22     [коллега, сидеть, рубиться, долбать, винд, мочь]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def lemmatization(words):\n",
    "    global morph\n",
    "    new_s = [morph.parse(word)[0].normal_form for word in words]\n",
    "    return new_s\n",
    "\n",
    "df.text = list(map(lemmatization, df.text))\n",
    "df.text.loc[19:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nROxZJjDcxiB"
   },
   "source": [
    "---\n",
    "\n",
    "Теперь необходимо удалить все слова, которые встречаются только 1 раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvoyixDGcxiB",
    "outputId": "a721d304-bc65-40ff-b6d2-e902e264109b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19          очень работать\n",
       "20                 история\n",
       "21    работа полный каждый\n",
       "22                  сидеть\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "def to_str(s):\n",
    "    new_s = ' '.join(j for j in s)\n",
    "    return new_s\n",
    "\n",
    "text_tokens = word_tokenize(' '.join(j for j in list(map(to_str, df.text))))\n",
    "text = nltk.Text(text_tokens)\n",
    "fdist = FreqDist(text)\n",
    "words_to_del = list(filter(lambda k: fdist[k] == 1, fdist))\n",
    "\n",
    "def delete_word(words):\n",
    "    global words_to_del\n",
    "    new_s = [word for word in words if word not in words_to_del]\n",
    "    return new_s\n",
    "\n",
    "df.text = list(map(delete_word, df.text))\n",
    "df.text = list(map(to_str, df.text))\n",
    "df.text.loc[19:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9J_Ei3tHcxiB"
   },
   "source": [
    "---\n",
    "\n",
    "На этом очистка данных завершена. Можно ли утверждать, что очистка идеальна? Однозначно нет! Но, ее может оказаться достаточно для решения нашей задачи.   \n",
    "Какие еще задачи могут возникнуть при очистке текстовых данных? Вот далеко неполный список:\n",
    "- Обработка больших документов и больших коллекций текстовых документов, которые не помещаются в память.\n",
    "- Извлечение текста из разметки, такой как HTML, PDF или другие структурированные форматы документов.\n",
    "- Транслитерация символов с других языков.\n",
    "- Декодирование символов Юникода в нормализованную форму, такую как UTF8\n",
    "- Обработка доменных имен, фраз и сокращений.\n",
    "- Обработка или удаление чисел, таких как даты и суммы.\n",
    "- Поиск и исправление распространенных опечаток и ошибок в написании.\n",
    "\n",
    "Можно очень долго заниматься очисткой и не достичь идеального результата. Лучше подойти к задаче итеративно - осуществить стандартную очистку и посмотреть на результат, если результат недостаточный, то провести дополнительные мероприятия по очистке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yu3rMjvscxiD",
    "outputId": "2ea9b46f-c37d-4b8d-ea9e-3bb10f96c1e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262, 200, 62)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_tokens), len(words_to_del), len(text_tokens) - len(words_to_del)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tc7MzjibcxiD"
   },
   "source": [
    "---\n",
    "\n",
    "После очистки в наших данных осталось всего 62 слова (это не уникальные повторяющиеся слова, уникальных всего 29). Этого мало для построения классификаторов, но позволило существенно сократить время для знакомства с очисткой данных. В вашем проекте после очистки останется более 1,4 млн слов.\n",
    "\n",
    "\n",
    "После очистки могут оказаться пустые твиты, т.е. эти твиты состояли из слов, записанных латиницей, стоп-слов, чисел, знаков припинания и уникальных слов. Такие твиты необходимо удалить из данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PVJRoKsdcxiD",
    "outputId": "e7f3b8c1-1720-4355-bb6f-f0e1693b12a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 6)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.text == '']), len(df[(df.text == '') & (df.positive == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJ_slJtrcxiE",
    "outputId": "e20513a8-0afb-4020-c3d1-6870b8c87ed3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(df[df.text == ''].index, axis = 0)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmtR-PzlcxiE"
   },
   "source": [
    "---\n",
    "\n",
    "После удаления пустых твитов у нас осталось 33 записи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlMO4_7icxiE"
   },
   "source": [
    "----\n",
    "\n",
    "# Задание 2\n",
    "\n",
    "Произведите очистку данных, сформированных в задании 1. По результатам очистки выведите на экран следующую информацию:   \n",
    "- Общее количество слов перед удалением слов, встречающихся 1 раз;\n",
    "- Количество слов, встречающихся 1 раз;\n",
    "- Итоговое количество слов;\n",
    "- Количество пустых твитов;\n",
    "- Из них позитивных твитов;\n",
    "- Количество твитов после удаления пустых.\n",
    "\n",
    "----\n",
    "\n",
    "***Совет:*** сохраняйте промежуточные результаты очистки, чтобы в случае неверных действий на каком-либо этапе не пересчитывать все предыдущие этапы\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svDU8K6fcxiE"
   },
   "source": [
    "Для разработки моделей нам необходимо оцифровать полученные данные. Мы воспользуемся двумя методами: мешком слов [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) и TF-IDF [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Но в начале необходимо разбить данные на обучающую и тестовую выборки.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvjctSJgcxiE"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.text, df.positive, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRHONwlncxiF"
   },
   "source": [
    "---\n",
    "\n",
    "Рассмотрим количество твитов в выборке для обучения, из них позитивных, и в выборке для теста, из них позитивных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sCJ_AalcxiF",
    "outputId": "b33d7336-ca4f-4cc8-cfd0-8e7846c07d70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 13, 7, 2)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), y_train.sum(), len(y_test), y_test.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozA-Cy-EcxiF"
   },
   "source": [
    "---\n",
    "\n",
    "### Кодировка данных   \n",
    "\n",
    "Кодируем наши данные мешком слов и tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gnjEXNCcxiG"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv_train = cv.fit_transform(X_train)\n",
    "cv_test = cv.transform(X_test)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_train = tfidf.fit_transform(X_train)\n",
    "tfidf_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saY0gM8ScxiG"
   },
   "source": [
    "---\n",
    "\n",
    "### Классификаторы\n",
    "\n",
    "Построим классификатор с помощью логистической регрессии:   \n",
    "на основе мешка слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDuFc9fXcxiG",
    "outputId": "d46d9629-73ce-4553-8a5b-707ef38911cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57         5\n",
      "           1       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.57         7\n",
      "   macro avg       0.70      0.70      0.57         7\n",
      "weighted avg       0.83      0.57      0.57         7\n",
      "\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        13\n",
      "           1       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.92      0.92      0.92        26\n",
      "weighted avg       0.92      0.92      0.92        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=21)\n",
    "lr.fit(cv_train, y_train)\n",
    "cv_pred = lr.predict(cv_test)\n",
    "print('test')\n",
    "print(classification_report(y_test, cv_pred))\n",
    "print('train')\n",
    "print(classification_report(y_train, lr.predict(cv_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npaM2-TmcxiH"
   },
   "source": [
    "---\n",
    "\n",
    "на основе tf-idf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xG84z4XrcxiH",
    "outputId": "7a051296-0db5-4ebb-f8d3-29fd75877602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57         5\n",
      "           1       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.57         7\n",
      "   macro avg       0.70      0.70      0.57         7\n",
      "weighted avg       0.83      0.57      0.57         7\n",
      "\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.96        26\n",
      "   macro avg       0.96      0.96      0.96        26\n",
      "weighted avg       0.96      0.96      0.96        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=21)\n",
    "lr.fit(tfidf_train, y_train)\n",
    "tfidf_pred = lr.predict(tfidf_test)\n",
    "print('test')\n",
    "print(classification_report(y_test, tfidf_pred))\n",
    "print('train')\n",
    "print(classification_report(y_train, lr.predict(tfidf_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFelSBv8cxiH"
   },
   "source": [
    "---\n",
    "\n",
    "Видно, что модели переобучены - это следствие малого количества данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7C5MM6FDcxiI"
   },
   "source": [
    "---\n",
    "\n",
    "Построим классификатор с помощью случайного леса [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html):   \n",
    "на основе мешка слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0MgSxj3HcxiI",
    "outputId": "7a834e82-99da-452f-8f93-9f513969d990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91         5\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.86         7\n",
      "   macro avg       0.92      0.75      0.79         7\n",
      "weighted avg       0.88      0.86      0.84         7\n",
      "\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        13\n",
      "           1       1.00      0.85      0.92        13\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.93      0.92      0.92        26\n",
      "weighted avg       0.93      0.92      0.92        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=3, n_jobs=-1, random_state=21)\n",
    "forest.fit(cv_train, y_train)\n",
    "cv_pred = forest.predict(cv_test)\n",
    "print('test')\n",
    "print(classification_report(y_test, cv_pred))\n",
    "print('train')\n",
    "print(classification_report(y_train, forest.predict(cv_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03sG8rNacxiI"
   },
   "source": [
    "---\n",
    "\n",
    "на основе tf-idf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMJm7XC4cxiI",
    "outputId": "06d16976-2733-4229-8965-543b74da2fee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         7\n",
      "   macro avg       1.00      1.00      1.00         7\n",
      "weighted avg       1.00      1.00      1.00         7\n",
      "\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        13\n",
      "           1       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.92        26\n",
      "   macro avg       0.92      0.92      0.92        26\n",
      "weighted avg       0.92      0.92      0.92        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest.fit(tfidf_train, y_train)\n",
    "tfidf_pred = forest.predict(tfidf_test)\n",
    "print('test')\n",
    "print(classification_report(y_test, tfidf_pred))\n",
    "print('train')\n",
    "print(classification_report(y_train, forest.predict(tfidf_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZJbQ24AcxiJ"
   },
   "source": [
    "---\n",
    "\n",
    "Получили очень хороший результат. Надо проверить, получится ли так же хорошо на всем объеме данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILZT8JtBcxiJ"
   },
   "source": [
    "---\n",
    "\n",
    "# Задание 3\n",
    "\n",
    "1. Кодировать данные методом мешка слов.\n",
    "2. Кодировать данные методом TF-IDF.\n",
    "3. Построить классификатор на основе логистической регрессии, используя мешок слов.\n",
    "4. Построить классификатор на основе логистической регрессии, используя TF-IDF.\n",
    "5. Построить классификатор на основе случайного леса, используя мешок слов.\n",
    "6. Построить классификатор на основе случайного леса, используя TF-IDF.\n",
    "7. Сделайте выводы о разработанных классификаторах.\n",
    "\n",
    "---\n",
    "\n",
    "При разбиении на обучающую и тестовую выборки, следует указать *test_size=0.3*\n",
    "\n",
    "---\n",
    "\n",
    "***Рекомендация:*** для случайного леса параметр n_estimator должен быть не менее 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuQ_OaBzcxiJ"
   },
   "source": [
    "***Рекомендация:*** в чек-листе содержится объемный обучающий материал, поэтому лучше не затягивать с решением заданий"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "d06_task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
